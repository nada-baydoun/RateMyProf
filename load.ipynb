{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(dotenv_path='.env.local')\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#existing_indexes = pc.list_indexes()\n",
    "# if \"rag\" not in existing_indexes:\n",
    "#     pc.create_index(\n",
    "#         name=\"rag\", dimension=768, metric=\"cosine\", spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "#     )\n",
    "# else:\n",
    "#     print(\"Index 'rag' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone.exceptions import PineconeApiException\n",
    "# api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    "# pc = Pinecone(api_key)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     existing_indexes = pc.list_indexes()\n",
    "#     if \"rag\" not in [idx['name'] for idx in existing_indexes['indexes']]:\n",
    "#         pc.create_index(\n",
    "#             name=\"rag\", dimension=768, metric=\"cosine\", spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "#         )\n",
    "#         print(\"Index 'rag' created successfully.\")\n",
    "#     else:\n",
    "#         print(\"Index 'rag' already exists, skipping creation.\")\n",
    "# except PineconeApiException as e:\n",
    "#     if e.status == 409:\n",
    "#         print(\"Index 'rag' already exists, no action taken.\")\n",
    "#     else:\n",
    "#         raise e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes: {'indexes': []}\n",
      "Index 'rag' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from pinecone.exceptions import PineconeApiException\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Pinecone\n",
    "api_key = \"b06218ed-b4ea-48db-a318-6e6870d7edd0\"\n",
    "pc = Pinecone(api_key)\n",
    "\n",
    "try:\n",
    "    # List existing indexes\n",
    "    existing_indexes = pc.list_indexes()\n",
    "    print(\"Existing indexes:\", existing_indexes)\n",
    "\n",
    "    # Check if the index already exists\n",
    "    index_names = [idx['name'] for idx in existing_indexes.get('indexes', [])]\n",
    "    if \"rag\" not in index_names:\n",
    "        pc.create_index(\n",
    "            name=\"rag\",\n",
    "            dimension=768,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "        print(\"Index 'rag' created successfully.\")\n",
    "    else:\n",
    "        print(\"Index 'rag' already exists, skipping creation.\")\n",
    "except PineconeApiException as e:\n",
    "    # Print the exception details for debugging\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Check if the status attribute exists and handle it\n",
    "    if hasattr(e, 'status') and e.status == 409:\n",
    "        print(\"Index 'rag' already exists, no action taken.\")\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'professor': 'Dr. John Smith',\n",
       "  'subject': 'Computer Science',\n",
       "  'stars': 5,\n",
       "  'review': 'Dr. Smith is an excellent professor who explains concepts very clearly.'},\n",
       " {'professor': 'Dr. Emily Johnson',\n",
       "  'subject': 'Mathematics',\n",
       "  'stars': 4,\n",
       "  'review': 'Dr. Johnson is very knowledgeable but can be a bit fast-paced.'},\n",
       " {'professor': 'Dr. Michael Brown',\n",
       "  'subject': 'Physics',\n",
       "  'stars': 3,\n",
       "  'review': 'The lectures are okay, but the exams are quite difficult.'},\n",
       " {'professor': 'Dr. Sarah Davis',\n",
       "  'subject': 'Chemistry',\n",
       "  'stars': 5,\n",
       "  'review': 'Amazing professor! Her labs are very well organized.'},\n",
       " {'professor': 'Dr. James Wilson',\n",
       "  'subject': 'History',\n",
       "  'stars': 2,\n",
       "  'review': 'Not very engaging, and the material is dry.'},\n",
       " {'professor': 'Dr. Linda Garcia',\n",
       "  'subject': 'Biology',\n",
       "  'stars': 4,\n",
       "  'review': 'Dr. Garcia is great, but her grading is tough.'},\n",
       " {'professor': 'Dr. Robert Martinez',\n",
       "  'subject': 'Political Science',\n",
       "  'stars': 3,\n",
       "  'review': 'Interesting lectures, but the workload is heavy.'},\n",
       " {'professor': 'Dr. Karen Anderson',\n",
       "  'subject': 'Psychology',\n",
       "  'stars': 5,\n",
       "  'review': 'Dr. Anderson is passionate about the subject and it shows in her teaching.'},\n",
       " {'professor': 'Dr. Richard Taylor',\n",
       "  'subject': 'Economics',\n",
       "  'stars': 4,\n",
       "  'review': 'Good professor, but sometimes hard to follow.'},\n",
       " {'professor': 'Dr. Jennifer Thomas',\n",
       "  'subject': 'Sociology',\n",
       "  'stars': 3,\n",
       "  'review': 'The content is interesting, but the lectures can be boring.'},\n",
       " {'professor': 'Dr. William Harris',\n",
       "  'subject': 'Philosophy',\n",
       "  'stars': 5,\n",
       "  'review': 'Dr. Harris encourages deep thinking and class discussions.'},\n",
       " {'professor': 'Dr. Elizabeth Clark',\n",
       "  'subject': 'Literature',\n",
       "  'stars': 4,\n",
       "  'review': 'Engaging lectures, but the reading load is heavy.'},\n",
       " {'professor': 'Dr. Charles Lewis',\n",
       "  'subject': 'Art History',\n",
       "  'stars': 3,\n",
       "  'review': 'The lectures are informative, but the assignments are unclear.'},\n",
       " {'professor': 'Dr. Barbara Robinson',\n",
       "  'subject': 'Anthropology',\n",
       "  'stars': 4,\n",
       "  'review': 'Interesting material, but can be hard to stay focused.'},\n",
       " {'professor': 'Dr. Thomas Walker',\n",
       "  'subject': 'Environmental Science',\n",
       "  'stars': 5,\n",
       "  'review': 'Dr. Walker is inspiring and passionate about environmental issues.'},\n",
       " {'professor': 'Dr. Jessica King',\n",
       "  'subject': 'Statistics',\n",
       "  'stars': 2,\n",
       "  'review': \"The class is challenging, and Dr. King doesn't explain things well.\"},\n",
       " {'professor': 'Dr. Mark Perez',\n",
       "  'subject': 'Engineering',\n",
       "  'stars': 5,\n",
       "  'review': 'Dr. Perez is great at making complex concepts easy to understand.'},\n",
       " {'professor': 'Dr. Laura Scott',\n",
       "  'subject': 'Music',\n",
       "  'stars': 4,\n",
       "  'review': 'Dr. Scott is very talented, but the class requires a lot of practice.'},\n",
       " {'professor': 'Dr. Steven Green',\n",
       "  'subject': 'Geology',\n",
       "  'stars': 3,\n",
       "  'review': 'The field trips are great, but the lectures can be dull.'},\n",
       " {'professor': 'Dr. Angela Young',\n",
       "  'subject': 'Education',\n",
       "  'stars': 4,\n",
       "  'review': 'Dr. Young is a caring professor, but her grading is strict.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "# data = json.load(open(\"reviews.json\"))\n",
    "# data['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "def scrape_ratemyprofessors(num_pages=5):\n",
    "    base_url = \"https://www.ratemyprofessors.com/search/teachers?query=*&sid=1073\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    all_reviews = []\n",
    "    \n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}&page={page}\"\n",
    "        print(f\"Scraping page {page}: {url}\")\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract professor information and reviews\n",
    "        professors = soup.find_all('div', class_='TeacherCard__StyledTeacherCard-syjs0d-0')\n",
    "        print(f\"Number of professors found on page {page}: {len(professors)}\")\n",
    "        \n",
    "        for professor in professors:\n",
    "            # ... (rest of the function remains the same)\n",
    "        \n",
    "            print(f\"Total reviews after page {page}: {len(all_reviews)}\")\n",
    "        \n",
    "        # Be respectful with request frequency\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    return all_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\hicha\\Downloads\\professor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for professor: Michael Beeson\n",
      "Navigating to search URL: https://www.ratemyprofessors.com/search/professors/12013?q=Michael%20Beeson\n",
      "Found profile URL: https://www.ratemyprofessors.com/professor/3\n",
      "Scraping professor profile from URL: https://www.ratemyprofessors.com/professor/3\n",
      "Extracting data...\n",
      "First Name: Michael\n",
      "Last Name: Beeson\n",
      "Scraping completed. Result:\n",
      "{'first_name': 'Michael', 'last_name': 'Beeson'}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def search_professor_selenium(name):\n",
    "    print(f\"Searching for professor: {name}\")\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    search_url = f'https://www.ratemyprofessors.com/search/professors/12013?q={name.replace(\" \", \"%20\")}'\n",
    "    print(f\"Navigating to search URL: {search_url}\")\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    try:\n",
    "        # Wait for search results to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a.TeacherCard__StyledTeacherCard-syjs0d-0.dLJIlx'))\n",
    "        )\n",
    "        \n",
    "        # Find the first professor profile link\n",
    "        profile_elements = driver.find_elements(By.CSS_SELECTOR, 'a.TeacherCard__StyledTeacherCard-syjs0d-0.dLJIlx')\n",
    "        if not profile_elements:\n",
    "            print(\"No profile elements found. Check if the selector is correct.\")\n",
    "            return None\n",
    "        \n",
    "        # Extract the href attribute and construct the full URL\n",
    "        relative_url = profile_elements[0].get_attribute('href')\n",
    "        profile_url = relative_url\n",
    "        print(f\"Found profile URL: {profile_url}\")\n",
    "        return profile_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding profile link: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def scrape_professor_selenium(url):\n",
    "    print(f\"Scraping professor profile from URL: {url}\")\n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.NameTitle__Name-dowf0z-0'))\n",
    "        )\n",
    "        \n",
    "        # Save page source for debugging\n",
    "        with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(driver.page_source)\n",
    "        \n",
    "        print(\"Extracting data...\")\n",
    "        \n",
    "        # Extract professor data\n",
    "        try:\n",
    "            first_name = driver.find_element(By.CSS_SELECTOR, 'div.NameTitle__Name-dowf0z-0 > span:first-of-type').text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding first name: {e}\")\n",
    "            first_name = None\n",
    "\n",
    "        try:\n",
    "            last_name = driver.find_element(By.CSS_SELECTOR, 'div.NameTitle__Name-dowf0z-0 > span:last-of-type').text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding last name: {e}\")\n",
    "            last_name = None\n",
    "        \n",
    "        # Extract similar professors\n",
    "        try:\n",
    "            similar_professors_elements = driver.find_elements(By.CSS_SELECTOR, 'span.SimilarProfessorListItem__TeacherNameSpan-x7cr0c-1.gMAFfH')\n",
    "            similar_professors = [element.text.strip() for element in similar_professors_elements]\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding similar professors: {e}\")\n",
    "            similar_professors = None\n",
    "        \n",
    "        # Print extracted data\n",
    "        print(f\"First Name: {first_name}\")\n",
    "        print(f\"Last Name: {last_name}\")\n",
    "        print(f\"Similar Professors: {similar_professors}\")\n",
    "        \n",
    "        return {\n",
    "            'first_name': first_name,\n",
    "            'last_name': last_name,\n",
    "            'similar_professors': similar_professors\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "professor_name = 'Michael Beeson'\n",
    "profile_url = search_professor_selenium(professor_name)\n",
    "if profile_url:\n",
    "    data = scrape_professor_selenium(profile_url)\n",
    "    print(\"Scraping completed. Result:\")\n",
    "    print(data)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "professor_name = 'Michael Beeson'\n",
    "profile_url = search_professor_selenium(professor_name)\n",
    "if profile_url:\n",
    "    data = scrape_professor_selenium(profile_url)\n",
    "    print(\"Scraping completed. Result:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(html)  \u001b[38;5;66;03m# Check the structure and update selectors as necessary\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "html = driver.page_source\n",
    "print(html)  # Check the structure and update selectors as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying professor ID: 1\n",
      "Trying professor ID: 2\n",
      "Trying professor ID: 3\n",
      "Trying professor ID: 4\n",
      "Trying professor ID: 5\n",
      "Trying professor ID: 6\n",
      "Trying professor ID: 7\n",
      "Trying professor ID: 8\n",
      "Trying professor ID: 9\n",
      "Trying professor ID: 10\n",
      "Trying professor ID: 11\n",
      "Trying professor ID: 12\n",
      "Trying professor ID: 13\n",
      "Trying professor ID: 14\n",
      "Trying professor ID: 15\n",
      "Trying professor ID: 16\n",
      "Trying professor ID: 17\n",
      "Trying professor ID: 18\n",
      "Trying professor ID: 19\n",
      "Trying professor ID: 20\n",
      "Trying professor ID: 21\n",
      "Trying professor ID: 22\n",
      "Trying professor ID: 23\n",
      "Trying professor ID: 24\n",
      "Trying professor ID: 25\n",
      "Trying professor ID: 26\n",
      "Trying professor ID: 27\n",
      "Trying professor ID: 28\n",
      "Trying professor ID: 29\n",
      "Trying professor ID: 30\n",
      "Trying professor ID: 31\n",
      "Trying professor ID: 32\n",
      "Trying professor ID: 33\n",
      "Trying professor ID: 34\n",
      "Trying professor ID: 35\n",
      "Trying professor ID: 36\n",
      "Trying professor ID: 37\n",
      "Trying professor ID: 38\n",
      "Trying professor ID: 39\n",
      "Trying professor ID: 40\n",
      "Trying professor ID: 41\n",
      "Trying professor ID: 42\n",
      "Trying professor ID: 43\n",
      "Trying professor ID: 44\n",
      "Trying professor ID: 45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_professors\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m scraped_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_ratemyprofessors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_professors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of scraped professors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(scraped_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scraped_data:\n",
      "Cell \u001b[1;32mIn[42], line 66\u001b[0m, in \u001b[0;36mscrape_ratemyprofessors\u001b[1;34m(start_id, max_professors, max_failures)\u001b[0m\n\u001b[0;32m     63\u001b[0m         consecutive_failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     65\u001b[0m     current_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Be respectful with request frequency\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_professors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m professors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_professors\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "def scrape_professor_by_id(professor_id):\n",
    "    url = f\"https://www.ratemyprofessors.com/professor/{professor_id}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    script_tag = soup.find('script', id='__NEXT_DATA__')\n",
    "    \n",
    "    if not script_tag:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        professor_data = json_data['props']['pageProps']['professorData']\n",
    "        \n",
    "        name = f\"{professor_data['firstName']} {professor_data['lastName']}\"\n",
    "        department = professor_data.get('department', 'N/A')\n",
    "        school = professor_data.get('school', {}).get('name', 'N/A')\n",
    "        rating = professor_data.get('avgRating', 'N/A')\n",
    "        num_ratings = professor_data.get('numRatings', 0)\n",
    "        \n",
    "        reviews = []\n",
    "        for rating in professor_data.get('ratings', [])[:5]:  # Get up to 5 recent reviews\n",
    "            review_text = rating.get('comment', 'No comment provided.')\n",
    "            reviews.append(review_text)\n",
    "        \n",
    "        return {\n",
    "            \"professor\": name,\n",
    "            \"department\": department,\n",
    "            \"school\": school,\n",
    "            \"rating\": rating,\n",
    "            \"num_ratings\": num_ratings,\n",
    "            \"reviews\": reviews\n",
    "        }\n",
    "    except (KeyError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "def scrape_ratemyprofessors(start_id=1, max_professors=3, max_failures=3):\n",
    "    all_professors = []\n",
    "    current_id = start_id\n",
    "    consecutive_failures = 0\n",
    "    \n",
    "    while len(all_professors) < max_professors and consecutive_failures < max_failures:\n",
    "        print(f\"Trying professor ID: {current_id}\")\n",
    "        professor_data = scrape_professor_by_id(current_id)\n",
    "        \n",
    "        if professor_data:\n",
    "            all_professors.append(professor_data)\n",
    "            consecutive_failures = 0\n",
    "            print(f\"Found professor: {professor_data['professor']}\")\n",
    "        else:\n",
    "            consecutive_failures += 1\n",
    "        \n",
    "        current_id += 1\n",
    "        time.sleep(random.uniform(1, 3))  # Be respectful with request frequency\n",
    "    \n",
    "    print(f\"Scraped {len(all_professors)} professors\")\n",
    "    return all_professors\n",
    "\n",
    "# Usage\n",
    "scraped_data = scrape_ratemyprofessors(start_id=1, max_professors=50, max_failures=100)\n",
    "print(f\"Number of scraped professors: {len(scraped_data)}\")\n",
    "if scraped_data:\n",
    "    print(f\"Sample scraped data: {scraped_data[0]}\")\n",
    "else:\n",
    "    print(\"No data scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('professors_data.json', 'r') as file:\n",
    "    scraped_data = json.load(file)\n",
    "\n",
    "# Process the data\n",
    "processed_data = [data for data in scraped_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in processed_data: 60\n",
      "Sample vector: {'id': 3, 'first_name': 'Michael', 'last_name': 'Beeson', 'similar_professors': ['Wendy Lee', 'Ashish Khanchandani', ''], 'ratings': ['Well... the subject of differentials & linear algebra is hard. That said, he does try to make it as easy as possible by using variation of example problems on the midterms. Sample midterm/ final was just like the real exam. Study, Study, Study. Got by this class by self-learning everything from khan academy and youtube. Textbook is useless', \"Math 123 can be one of the hardest courses for engineering students at SJSU. Therefore, I believe that Prof. Beeson has done the best he could. I don't know why people keep complaining about partial credit, but I agree with his point of view - If you want to become an engineer, you are not allowed to make mistakes. That's life, deal with it.\", 'Prof. Beeson is extremely apathetic to students, he does not care if you pass or fail. On exams, he does not give any partial credit, which is extremely odd for a math class. Even if you did the problem correct but made a mistake, you lose all your points for one question because Mr. Beeson expects you to be perfect. Strongly do not recommend him', 'I sleep in class and I still manage to average a B grade for the 3 midterms.', \"He's so boring and even makes me feel sleepy. I always plays computer games during classes and have to learn the knowledge by myself\", \"2 midterms, 1 final. 10 questions total, and doesn't give partial credit or any extra credit. His voice is very monotone, making it difficult to pay attention. What's worse is trying to understand his handwriting. Half the time, I couldn't read what he wrote because it was so tiny and pretty much chicken scratch. Try to avoid taking him.\", 'Decent professor, knows his material really well but isnt effective in teaching it to other... tests and exams arent too bad they are similar to the sample exams he gives... similar concepts just different problems... quizzes time to time... be prepared to learn the majority of the lectures on your own...', 'DO NOT take this professor, terrible at speaking and explaining. Tests are only a few questions and a lot of points. Gave one section an easier final than the other, and does not give partial credit.', \"I took calculus before so the class wasn't as hard however, his tests are only 10 problems usually and each is worth a ton and he doesn't give partial credit usually so you have to exact. No calculators for his class and random quizzes in class from time to time. Hw is easy all done on an online program no effort, will you learn calculus, maybe.\", 'This proffesor is a total joke, avoid him at all costs. He manages to take a not too challenging subject into something impossible.']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of vectors in processed_data: {len(processed_data)}\")\n",
    "print(f\"Sample vector: {processed_data[0] if processed_data else 'No data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes: {'indexes': [{'deletion_protection': 'disabled',\n",
      "              'dimension': 768,\n",
      "              'host': 'rag-n9979me.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'rag',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n",
      "Index 'rag' already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from pinecone.exceptions import PineconeApiException\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Pinecone\n",
    "api_key = \"b06218ed-b4ea-48db-a318-6e6870d7edd0\"\n",
    "# Ensure correct endpoint and environment\n",
    "pc = Pinecone(api_key, environment=\"us-east-1\")\n",
    "\n",
    "try:\n",
    "    # List existing indexes\n",
    "    existing_indexes = pc.list_indexes()\n",
    "    print(\"Existing indexes:\", existing_indexes)\n",
    "\n",
    "    # Check if the index already exists\n",
    "    index_names = [idx['name'] for idx in existing_indexes.get('indexes', [])]\n",
    "    if \"rag\" not in index_names:\n",
    "        pc.create_index(\n",
    "            name=\"rag\",\n",
    "            dimension=768,  # Use the correct dimension here\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "        print(\"Index 'rag' created successfully.\")\n",
    "    else:\n",
    "        print(\"Index 'rag' already exists, skipping creation.\")\n",
    "except PineconeApiException as e:\n",
    "    # Print the exception details for debugging\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Check if the status attribute exists and handle it\n",
    "    if hasattr(e, 'status') and e.status == 409:\n",
    "        print(\"Index 'rag' already exists, no action taken.\")\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty review for professor 157\n",
      "Upserted count: 598\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Configure Gemini API key\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_api_key = \"b06218ed-b4ea-48db-a318-6e6870d7edd0\"  # Replace with your actual API key\n",
    "pinecone_host = \"https://rag-n9979me.svc.aped-4627-b74a.pinecone.io\"\n",
    "pinecone_environment = \"us-east-1\"  # Ensure this matches your Pinecone environment\n",
    "pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_environment, host=pinecone_host)\n",
    "\n",
    "# Reference your Pinecone index\n",
    "index = pc.Index(\"rag\")  # Replace with your actual index name\n",
    "\n",
    "data = []  # Data to be upserted\n",
    "model = 'models/embedding-001'\n",
    "\n",
    "# Assuming processed_data is a list of dictionaries with professor info\n",
    "for professor in processed_data:\n",
    "    for review in professor['ratings']:\n",
    "        # Skip empty reviews\n",
    "        if not review.strip():\n",
    "            print(f\"Skipping empty review for professor {professor['id']}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Generate embedding using Gemini\n",
    "            embedding_response = genai.embed_content(\n",
    "                model=model,\n",
    "                content=review,\n",
    "                task_type=\"retrieval_document\"\n",
    "            )\n",
    "            \n",
    "            # Check for the embedding key and ensure it contains data\n",
    "            embedding = embedding_response.get('embedding')\n",
    "            if not embedding:\n",
    "                print(f\"No embedding returned for review: {review}\")\n",
    "                continue\n",
    "            \n",
    "            # Append data to the list for upsert\n",
    "            data.append({\n",
    "                \"id\": f\"{professor['id']}_{len(data)}\",  # Unique ID for each review\n",
    "                \"values\": embedding,\n",
    "                \"metadata\": {\n",
    "                    \"first_name\": professor[\"first_name\"],\n",
    "                    \"last_name\": professor[\"last_name\"],\n",
    "                    \"similar_professors\": professor[\"similar_professors\"],\n",
    "                    \"review\": review\n",
    "                }\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding for review: {review}. Error: {e}\")\n",
    "\n",
    "# Upsert data to Pinecone\n",
    "try:\n",
    "    upsert_response = index.upsert(\n",
    "        vectors=data,  # Ensure this matches the expected input format for Pinecone\n",
    "        namespace=\"ns1\"\n",
    "    )\n",
    "    print(f\"Upserted count: {upsert_response.get('upserted_count', 0)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error upserting data to Pinecone: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
